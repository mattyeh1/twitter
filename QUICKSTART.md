# ğŸš€ Quick Start Guide

## Inicio RÃ¡pido (5 minutos)

### OpciÃ³n A: Docker (MÃ¡s FÃ¡cil)

```bash
# 1. Copiar configuraciÃ³n
cp .env.example .env

# 2. Iniciar todo
docker-compose up -d

# 3. Abrir en navegador
# http://localhost:5000
```

### OpciÃ³n B: Local

```bash
# 1. Instalar dependencias
pip install -r requirements.txt

# 2. Instalar Redis
# Ubuntu: sudo apt-get install redis-server
# macOS: brew install redis
# Windows: https://github.com/microsoftarchive/redis/releases

# 3. Iniciar
./start_local.sh      # Linux/Mac
start_local.bat       # Windows
```

---

## âœ… Verificar que Funciona

### 1. Acceder al Dashboard
Abre: http://localhost:5000

### 2. Agregar un Perfil
- Click en "Agregar Nuevo Perfil"
- Username: `elonmusk` (sin @)
- Intervalo: `12` horas
- Click "Agregar Perfil"

### 3. Scrapear
- Click "ğŸš€ Scrapear Ahora" en @elonmusk
- VerÃ¡s progreso en tiempo real (esquina superior derecha)
- En ~2 minutos, verÃ¡s los tweets

### 4. Ver Resultados
- Click "ğŸ‘ Ver Tweets" para ver los tweets scrapeados
- O usa "Buscar Tweets" para buscar por palabras clave

---

## ğŸ¯ Probar Scraping Concurrente

Abre 3 navegadores/pestaÃ±as diferentes y haz click en "Scrapear Ahora" en diferentes perfiles **al mismo tiempo**.

VerÃ¡s que:
- âœ… Los 3 scrapings corren **en paralelo**
- âœ… Cada uno tiene su propio driver
- âœ… No hay conflictos

**Antes**: Solo 1 a la vez, los demÃ¡s esperaban
**Ahora**: Hasta 3 simultÃ¡neos (configurable)

---

## ğŸ“Š Monitoreo

### Dashboard del Sistema
http://localhost:5000/monitoring

- Estado del pool de drivers
- Drivers activos vs disponibles
- EstadÃ­sticas de uso

### Flower (Celery Monitor)
http://localhost:5555

- Tareas en cola/activas/completadas
- GrÃ¡ficos de performance
- Workers activos

---

## âš™ï¸ ConfiguraciÃ³n RÃ¡pida

### MÃ¡s Scrapers SimultÃ¡neos

Editar `.env`:
```bash
DRIVER_POOL_SIZE=5  # Ahora hasta 5 simultÃ¡neos
```

Reiniciar:
```bash
docker-compose restart
# O Ctrl+C y ./start_local.sh
```

### Cambiar Puerto
```bash
# .env
FLASK_PORT=8080

# Ahora: http://localhost:8080
```

---

## ğŸ› SoluciÃ³n de Problemas

### Redis no conecta
```bash
# Verificar
redis-cli ping

# Debe responder: PONG
```

### Celery no procesa tareas
```bash
# Ver logs
docker-compose logs celery_worker

# Reiniciar
docker-compose restart celery_worker
```

### Chrome no funciona
```bash
# Instalar Chrome
sudo apt-get install google-chrome-stable
```

---

## ğŸ“ Archivos Importantes

```
.env                 # ConfiguraciÃ³n (copiar de .env.example)
run.py               # Iniciar aplicaciÃ³n
docker-compose.yml   # Todos los servicios
README.md            # DocumentaciÃ³n completa
```

---

## ğŸ“ Siguiente Paso

Lee el [README.md](README.md) completo para:
- Arquitectura del sistema
- CÃ³mo funciona el pool de drivers
- Escalabilidad
- Deployment en producciÃ³n

---

**Â¡Listo! Ya tienes scraping concurrente profesional ğŸš€**
